<!DOCTYPE html>

<html>

<head>
    <style>
        td,
        th {
            border: 0px solid black;
        }

        img {
            padding: 5px;
        }
    </style>

    <title>AWRaCLe</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="shortcut icon" href="./static/images/jhu_web.png" />

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">
    <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title"> <i>AWRaCLe</i> : All-Weather Image Restoration using Visual In-Context Learning
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Group of first four authors -->
                            <div class="authors-group">
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=SGty2eUAAAAJ&hl=en" target="_blank">Sudarshan Rajagopalan*</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en"
                                        target="_blank">Vishal M. Patel</a>
                                </span>
                            </div>
                        </div>


                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Johns Hopkins University</span>
                        </div>

                        <div class="column has-text-centered">
                            <a href="as"></a>
                            </span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <!-- <span class="link-block">
                                    <a href=""
                                        class="external-link button is-normal is-rounded is-dark" target="_blank">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span> -->
                                <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary material</span>
                </a>
              </span> -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>Arxiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code (Coming Soon!)</span>
                                    </a>
                                </span>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">

                    <h2 class="title is-3">Abstract</h2>
                    <img src="./static/images/intro_viz.png" alt="" border="0" height="600" width="1500">
                    <img src="./static/images/intro.png" alt="" style="border:0; height:500px; width:1500px;">
                    <div class="content has-text-justified">
                        <p>
                          Illustration of AWRaCLe: Our visual in-context learning approach for all-weather image restoration. The first two rows are the context pair. 
                          The third row is the query image that needs to be restored and the fourth row is our output. 
                          (d) and (e) show results for selective removal of haze and snow, respectively, from an image containing their mixture.  
                        </p>
                        <p>
                            All-Weather Image Restoration (AWIR) under adverse weather conditions is a challenging task due to the presence of different types of degradations. 
                            Prior research in this domain relies on extensive training data but lacks the utilization of additional contextual information for restoration guidance. 
                            Consequently, the performance of existing methods is limited by the degradation cues that are learnt from individual training samples. 
                            Recent advancements in visual in-context learning have introduced generalist models that are capable of addressing multiple computer vision tasks simultaneously by using 
                            the information present in the provided context as a prior. 
                            In this paper, we propose \textit{\textbf{A}ll-\textbf{W}eather Image \textbf{R}estor\textbf{a}tion using Visual In-\textbf{C}ontext \textbf{Le}arning} (AWRaCLe), a novel 
                            approach for AWIR that innovatively utilizes degradation-specific visual context information to steer the image restoration process. 
                            To achieve this, AWRaCLe incorporates Degradation Context Extraction (DCE) and Context Fusion (CF) to seamlessly integrate degradation-specific features from the context 
                            into an image restoration network. 
                            The proposed DCE and CF blocks leverage CLIP features and incorporate attention mechanisms to adeptly learn and fuse contextual information. 
                            These blocks are specifically designed for visual in-context learning under all-weather conditions and are crucial for effective context utilization. 
                            Through extensive experiments, we demonstrate the effectiveness of AWRaCLe for all-weather restoration and show that our method advances the state-of-the-art in AWIR. 
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->

            <!-- Paper video. -->

            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Proposed Approach
                            <div class="content has-text-justified">
                                <h5 class="subtitle has-text-centered"></h5>

                                <img src="./static/images/main_archi.png" alt="" border=0 height=500 width=1500></img></
                                <p>
                                Block diagram of the proposed visual in-context learning approach for AWIR. 
                                CLIP features are extracted from $I_{\texttt{d}}$ and $I_{\texttt{c}}$ which are subsequently fed to DCE blocks at different decoder levels, $l$. 
                                CF blocks then fuse the degradation information obtained from the DCE blocks with decoder features, $F^{l}$, from the query image $I_{\texttt{q}}$. Finally, the restored image is generated.
                                </p>
                                <p>
                                    The main idea of our approach involves extracting relevant degradation-context such as the type and visual characteristics of degradations from a given image-ground truth pair to effectively restore a 
                                    query image with the same type of degradation. Toward this aim, we propose Degradation Context Extraction (DCE) and Context Fusion (CF) blocks that learn context information and fuse it with an 
                                    image restoration network to facilitate the restoration process. Specifically, we integrate our DCE and CF blocks with a slightly modified version of the Restormer network (see supplementary for details).
                                    The DCE and CF blocks are added at each decoder level of Restormer for propagation of context information (multi-level fusion). 
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Results and Comparison
                            <div class="content has-text-justified">
                                <h5 class="subtitle has-text-centered"></h5>

                                <img src="./static/images/main_archi.png" alt="" border=0 height=500 width=1500></img></
                                    <p>
                                    Quantitative comparisons of AWRaCLe with SOTA on the test sets described in Sec. 4.2. The values indicated are
                                    placeholders for PSNR/SSIM. Degradation type (S-Snow, R-Rain, H-Haze) is indicated within brackets. The best result is in
                                    bold, and second best is underlined.
                                    </p>

                                <p>
                                    Our approach achieves sota....
                                </p>

                                <p>
                                    Qualitative comparisons of AWRaCLe with top performing approaches (TSMC, PromptIR and DiffUIR) on SOTS,
                                    Rain100L, Rain100H and Snow100k datasets. Zoomed-in patches are provided for examining fine details.
                                </p>

                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section class="section" id="BibTeX">
                <div class="container content is-max-desktop">
                    <h2 class="title">BibTeX</h2>
                    <pre><code>@article{bibtexnarayan2024facexformer,
    title={FaceXFormer: A Unified Transformer for Facial Analysis},
    author={Narayan, Kartik and VS, Vibashan and Chellappa, Rama and Patel, Vishal M},
    journal={arXiv preprint arXiv:2403.12960},
    year={2024}
}
</code></pre>
                </div>
            </section>

            <section class="section">
                <div class="container is-max-desktop content">
                    <h5 class="title" style="font-size: 10px;"> Acknowledgement: The website template is taken from
                        <span class="author-block">
                            <a href="https://nerfies.github.io/" target="_blank">Nerfies</a>
                    </h5>

                </div>
            </section>

            <script>
                const viewers = document.querySelectorAll(".image-compare");
                viewers.forEach((element) => {
                    let view = new ImageCompare(element, {
                        hoverStart: true,
                        addCircle: true
                    }).mount();
                });

                $(document).ready(function () {
                    var editor = CodeMirror.fromTextArea(document.getElementById("bibtex"), {
                        lineNumbers: false,
                        lineWrapping: true,
                        readOnly: true
                    });
                    $(function () {
                        $('[data-toggle="tooltip"]').tooltip()
                    })
                });
            </script>
</body>

</html>
